p8105_hw2_lx2346
================
linshan xie
2024-09-25

# Problem 1

Prepare for the packages that may be used

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

## import and clean the NYC Transit data

``` r
nyc_tran = read_csv("./data of hw2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",na = "") |>
  janitor::clean_names() |>
  select(line, station_name, station_latitude,station_longitude, route1:route11, entry, vending, entrance_type,ada) |>
  mutate( entry = case_match( entry , "YES"  ~ TRUE, "NO" ~ FALSE)) |>
  mutate( vending = case_match(vending , "YES"  ~ TRUE, "NO" ~ FALSE))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Describe the NYC Transit Data

**The NYC transit data set has 1868 rows and 19 columns. It is a
1868✖️19 table.**  
**The variables in the dataset are line, station_name, station_latitude,
station_longitude, route1, route2, route3, route4, route5, route6,
route7, route8, route9, route10, route11, entry, vending, entrance_type,
ada.**  
To sum up, the dataset lists each of the entry/exit in each subway
station. It lists whether or not it is a entry, whether or not it has a
vending, whether or not it has a ADA compliance and the entrance type of
each entry/exit. It also lists the information about the station, like
which line and route it belongs to and the station’s locaton (longitude
and latitude).

## Describe what cleaning work I’ve done above.

1.  Clean the names of the dataset  
2.  Combine the routes from route1 to route11 into 1 variable with
    column name routes_served  
3.  Remove blank variable at routes_served  
4.  Select the route, station name, station latitude, station longitude,
    service route, entrance, vending machine, entrance_type, motor
    variable required by the problem  
5.  Convert the entry and vending variable from character (YES vs NO) to
    a logical variable  

## Are these data tidy?

This data is not tidy because it uses eleven lines of variables(route1 :
route 11) to display information about the route.

## Answer the following questions using these data:

**1. How many distinct stations are there? Note that stations are
identified both by name and by line (e.g. 125th St 8th Avenue; 125st
Broadway; 125st Lenox)**  
  
There are 465 distinct stations.

**2. How many stations are ADA compliant?**  

``` r
ada_true = filter(nyc_tran, ada == TRUE)
nrow(distinct(ada_true, station_name, line))
```

    ## [1] 84

So there are 73 distinct stations which are ADA compliant.  

**3. What proportion of station entrances / exits without vending allow
entrance?**  
  
0.3770492

### Reformat data making route number and route name distinct variables

``` r
nyc_tran_2 = read_csv("./data of hw2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",na = "") |>
  janitor::clean_names() |>
  mutate(across(starts_with("route"), as.character)) |>
  pivot_longer(
    route1:route11,
    names_to = "route_number", 
    values_to = "route_name",
    names_prefix = "route")
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#find the distinct station serves A route & ada. 
serve_a = filter(nyc_tran_2, route_name == "A")
serve_a_ada = filter(serve_a, ada == TRUE)
```

So there are 60 distinct stations serves A. And among those stations
serves A, there are 17 stations are ADA compliant.

# Problem 2

## import and clean mr_trash data

``` r
library(readxl)
mr_trash = read_excel("./data of hw2/202409 Trash Wheel Collection Data.xlsx", range = "A2:N653") |>
  janitor::clean_names() |>
  mutate(sports_balls = round(sports_balls)) |>
  mutate(sports_balls = as.integer(sports_balls)) |>
  mutate(type = "Mr.")
```

## use the same way import Professor Trash Wheel and Gwynnda data

``` r
# import professor trash wheel
prof_trash = read_excel("./data of hw2/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M120") |>
  janitor::clean_names() |>
  mutate(type = "Professor") |>
  mutate(year = as.character(year))
# import Gwynnda Trash Wheel
gwy_trash = read_excel("./data of hw2/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L265") |>
  janitor::clean_names() |>
  mutate(type = "Gwynnda") |>
  mutate(year = as.character(year))
```

## combine the 3 dataset

``` r
trash_df = bind_rows( prof_trash, gwy_trash, mr_trash)
```

## Write a paragraph about these data

**The trash_df has 1032 rows and 15 columns. It is a 1032✖15 table.**  
There are 1032 observations. The variables in the dataset are dumpster,
month, year, date, weight_tons, volume_cubic_yards, plastic_bottles,
polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers,
homes_powered, type, sports_balls, in which, there are mainly three
types of trash wheels in the data frame, which are Mr. Trash Wheel,
Professor Trash Wheel and Gwynnda Trash Wheel. The variable numbers
shows the exact number of trash that the dumpster collect. Home_powered
means Each ton of trash equates to on average 500 kilowatts of
electricity. An average household will use 30 kilowatts per day.  

### What was the total weight of trash collected by Professor Trash Wheel?

The total weight of trash Professor Trash Wheel collect is 246.74 tons.

### What was the total number of cigarette butts collected by Gwynnda in June of 2022?

The total number of cigarette butts collected by Gwynnda in June of 2022
is 1.812^{4}

# Problem 3

## Part 1: create a single, well-organized dataset with all the information

First of all, read all these tables.

``` r
bakers = read_csv("./data of hw2/gbb_datasets/bakers.csv") |>
  janitor::clean_names()
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes = read_csv("./data of hw2/gbb_datasets/bakes.csv")|>
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
result = read_csv("./data of hw2/gbb_datasets/results.csv", skip = 2, na = "NA")|>
  janitor::clean_names() |>
  mutate(
    result = case_match(
      result,
      "IN" ~ "stayed in",
      "OUT" ~ "Eliminated",
      "STAR BAKER" ~ "Star Baker", 
      "WINNER" ~ "Series Winner",
      "Runner-up" ~ "Series Runner up",
      "WD" ~ "withdrew")
    )
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Wrangle through the datasets

``` r
bakers = rename(bakers, baker_full_name = baker_name) |>
  mutate(baker_first_name = sapply(strsplit(baker_full_name, " "), function(x) x[1])) |>
  select(baker_full_name, baker_first_name, everything())
bakes = rename(bakes, baker_first_name = baker)
result = rename(result, baker_first_name = baker)
```

see if the data in the bakes and result set are correct

``` r
anti_join(bakes, bakers, by = c("baker_first_name","series"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker_first_name signature_bake                    show_stopper
    ##    <dbl>   <dbl> <chr>            <chr>                             <chr>       
    ## 1      2       1 "\"Jo\""         Chocolate Orange CupcakesOrange … Chocolate a…
    ## 2      2       2 "\"Jo\""         Caramelised Onion, Gruyere and T… Raspberry a…
    ## 3      2       3 "\"Jo\""         Stromboli flavored with Mozzarel… Unknown     
    ## 4      2       4 "\"Jo\""         Lavender Biscuits                 Blueberry M…
    ## 5      2       5 "\"Jo\""         Salmon and Asparagus Pie          Apple and R…
    ## 6      2       6 "\"Jo\""         Rum and Raisin Baked Cheesecake   Limoncello …
    ## 7      2       7 "\"Jo\""         Raspberry & Strawberry Mousse Ca… Pain Aux Ra…
    ## 8      2       8 "\"Jo\""         Raspberry and Blueberry Mille Fe… Mini Victor…

For “Jo” in bakes, I find a strange ““across the Jo, so I tried to
change it into Jo and do anti join again:

``` r
bakes = bakes |>
  mutate(baker_first_name = recode(baker_first_name, "\"Jo\"" = "Jo"))
```

Let’s see what is in result but not in bakers

``` r
anti_join(result, bakers, by = c("baker_first_name","series"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker_first_name technical result       
    ##    <dbl>   <dbl> <chr>                <dbl> <chr>        
    ## 1      2       1 Joanne                  11 stayed in    
    ## 2      2       2 Joanne                  10 stayed in    
    ## 3      2       3 Joanne                   1 stayed in    
    ## 4      2       4 Joanne                   8 stayed in    
    ## 5      2       5 Joanne                   6 stayed in    
    ## 6      2       6 Joanne                   1 Star Baker   
    ## 7      2       7 Joanne                   3 stayed in    
    ## 8      2       8 Joanne                   1 Series Winner

It is shown that the person who has a first name Joanne is not in the
list of bakers but in the list of result. The person Joanne is shown in
series 2, episode 1~8, it is just the same situation with Jo as it
listed in the bakes set. If I use it reversely…

``` r
anti_join(bakers, result, by = c("baker_first_name","series"))
```

    ## # A tibble: 1 × 6
    ##   baker_full_name baker_first_name series baker_age baker_occupation hometown   
    ##   <chr>           <chr>             <dbl>     <dbl> <chr>            <chr>      
    ## 1 Jo Wheatley     Jo                    2        41 Housewife        Ongar, Ess…

So I strongly suspect that the person Joanne in result set is the Jo in
bakers and bakes datasets.

``` r
result = result |>
  mutate(baker_first_name = recode(baker_first_name, "Joanne" = "Jo"))
```

So far, all these datasets are clean and correct. Let’s merge them
together.

## Combine the 3 datasets

``` r
baker_df_all = left_join(bakers,result, by = c("baker_first_name","series"))  |>
  left_join(bakes, by = c("baker_first_name","series","episode" )) |>
  select(baker_full_name, baker_first_name, baker_age, baker_occupation, hometown, series,episode, signature_bake, show_stopper, everything())
write_csv(baker_df_all, "./data of hw2/baker_df_all.csv")
```

So, in this data set, I’ve conclude all the bakers information (full
names, first names, age, occupation and hometown) and the series and
episode they take part in the show. I’ve also shown the signature bake
and show stopper of their bake in each episode. The technical and the
result of them either.

## Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10

``` r
star_winner = baker_df_all |>
  filter(series >= 5 & series <= 10) |>
  filter(result %in% c("Star Baker","Series Winner" )) |>
  arrange(series, episode)
star_winner
```

    ## # A tibble: 60 × 11
    ##    baker_full_name   baker_first_name baker_age baker_occupation hometown series
    ##    <chr>             <chr>                <dbl> <chr>            <chr>     <dbl>
    ##  1 Nancy Birtwhistle Nancy                   60 Retired Practic… Barton-…      5
    ##  2 Richard Burr      Richard                 38 Builder          Mill Hi…      5
    ##  3 Luis Troyano      Luis                    42 Graphic Designer Poynton…      5
    ##  4 Richard Burr      Richard                 38 Builder          Mill Hi…      5
    ##  5 Kate Henry        Kate                    41 Furniture Resto… Brighto…      5
    ##  6 Chetna Makan      Chetna                  35 Fashion Designer Broadst…      5
    ##  7 Richard Burr      Richard                 38 Builder          Mill Hi…      5
    ##  8 Richard Burr      Richard                 38 Builder          Mill Hi…      5
    ##  9 Richard Burr      Richard                 38 Builder          Mill Hi…      5
    ## 10 Nancy Birtwhistle Nancy                   60 Retired Practic… Barton-…      5
    ## # ℹ 50 more rows
    ## # ℹ 5 more variables: episode <dbl>, signature_bake <chr>, show_stopper <chr>,
    ## #   technical <dbl>, result <chr>

As you can see from this table, **Most of the people who end up winning
series winners have taken more than one star baker in the first few
episodes of this season** (which is quite predictable), such as Nancy in
Season 5, Nadiya in Season 6, Candice in Season 7, Sophie in Season 8,
and Rahul in Season 9, but there was a surprise, in season 10, **Steph**
had a total of **4 star bakers**, which made him the strongest candidate
for series winner, but in episode 10 the series winner was David.

## Now for the viewers!

``` r
viewers = read_csv("./data of hw2/gbb_datasets/viewers.csv", na = "NA")|>
  janitor::clean_names() |>
  pivot_longer(
    series_1:series_10,
    names_to = "series",
    values_to = "viewership",
    names_prefix = "series_"
  ) |>
  select(series, episode, viewership) |>
  mutate(series = as.numeric(series)) |>
  arrange(series, episode)
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewers, n = 10)
```

    ## # A tibble: 10 × 3
    ##    series episode viewership
    ##     <dbl>   <dbl>      <dbl>
    ##  1      1       1       2.24
    ##  2      1       2       3   
    ##  3      1       3       3   
    ##  4      1       4       2.6 
    ##  5      1       5       3.03
    ##  6      1       6       2.75
    ##  7      1       7      NA   
    ##  8      1       8      NA   
    ##  9      1       9      NA   
    ## 10      1      10      NA

### Next, calculate the average viewership in Season 1 and Season 5.

Notice: There are some NA values in the dataset. The average viewership
in Season 1 is 2.77.  
The average viewership in Season 5 is 10.0393.
