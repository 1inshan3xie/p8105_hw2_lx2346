---
title: "p8105_hw2_lx2346"
author: "linshan"
date: "2024-09-25"
output: github_document
---

# Problem 1
Prepare for the packages that may be used
```{r}
library(tidyverse)
```
## import and clean the NYC Transit data
```{r}
nyc_tran = read_csv("./data of hw2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",na = "") |>
  janitor::clean_names() |>
  mutate(across(starts_with("route"), as.character)) |>
  pivot_longer(
    route1:route11,
    names_to = NULL, 
    values_to = "routes_served") |>
  filter(routes_served != "") |>
  select(line, station_name, station_latitude,station_longitude, routes_served, entry, vending, entrance_type,ada) |>
  mutate( entry = case_match( entry , "YES"  ~ TRUE, "NO" ~ FALSE)) |>
  mutate( vending = case_match(vending , "YES"  ~ TRUE, "NO" ~ FALSE))
```
## Describe what cleaning work I've done above.
1. Clean the names of the dataset\
2. Combine the routes from route1 to route11 into 1 variable with column name routes_served\
3. Remove blank variable at routes_served\
4. Select the route, station name, station latitude, station longitude, service route, entrance, vending machine, entrance_type, motor variable required by the problem\
5. Convert the entry and vending variable from character (YES vs NO) to a logical variable\

## Describe the NYC Transit Data
**The NYC transit data set has `r nrow(nyc_tran)` rows and `r ncol(nyc_tran)` columns. It is a `r nrow(nyc_tran)`✖️`r ncol(nyc_tran)` table.**\
**The variables in the dataset are `r names(nyc_tran)`.**\
To sum up, the dataset lists each of the entry/exit in each subway station. It lists whether or not it is a entry, whether or not it has a vending,  whether or not it has a ADA compliance and the entrance type of each entry/exit. It also lists the information about the station, like which line and route it belongs to and the station's locaton (longitude and latitude).

## Answer the following questions using these data:
**1. How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox)**\
\
There are `r nrow(distinct(nyc_tran,station_name))` distinct stations.

**2. How many stations are ADA compliant?**\
```{r}
ada_true = filter(nyc_tran, ada == TRUE)
nrow(distinct(ada_true, station_name))
```
So there are `r nrow(distinct(ada_true, station_name))` distinct stations which are ADA compliant.\

**3. What proportion of station entrances / exits without vending allow entrance?**\
\
`r nrow(filter(nyc_tran, vending == FALSE))/nrow(nyc_tran)`

### Reformat data making route number and route name distinct variables
```{r}
nyc_tran_2 = read_csv("./data of hw2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",na = "") |>
  janitor::clean_names() |>
  mutate(across(starts_with("route"), as.character)) |>
  pivot_longer(
    route1:route11,
    names_to = "route_number", 
    values_to = "route_name",
    names_prefix = "route") |>
  filter(route_name != "")
#find the distinct station serves A route & ada. 
serve_a = filter(nyc_tran_2, route_name == "A")
serve_a_ada = filter(serve_a, ada == TRUE)
```

So there are `r nrow(distinct(serve_a, station_name))` distinct stations serves A. And among those stations serves A, there are `r nrow(distinct(serve_a_ada, station_name))` stations are ADA compliant.

# Problem 2
## import and clean mr_trash data
```{r}
library(readxl)
mr_trash = read_excel("./data of hw2/202309 Trash Wheel Collection Data.xlsx", range = "A2:N586") |>
  janitor::clean_names() |>
  mutate(sports_balls = round(sports_balls)) |>
  mutate(sports_balls = as.integer(sports_balls)) |>
  pivot_longer(
    plastic_bottles: sports_balls,
    names_to = "type_of_trash",
    values_to = "numbers"
  ) |>
  mutate(type = "Mr.")
```

## use the same way import Professor Trash Wheel and Gwynnda data
```{r}
# import professor trash wheel
prof_trash = read_excel("./data of hw2/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") |>
  janitor::clean_names() |>
  pivot_longer(
    plastic_bottles: wrappers,
    names_to = "type_of_trash",
    values_to = "numbers"
  ) |>
  mutate(type = "Professor") |>
  mutate(year = as.character(year))
# import Gwynnda Trash Wheel
gwy_trash = read_excel("./data of hw2/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L157") |>
  janitor::clean_names() |>
  pivot_longer(
    plastic_bottles: wrappers,
    names_to = "type_of_trash",
    values_to = "numbers"
  ) |>
  mutate(type = "Gwynnda") |>
  mutate(year = as.character(year))
```

## combine the 3 dataset
```{r}
trash_df = bind_rows( prof_trash, gwy_trash, mr_trash)
```

## Write a paragraph about these data
**The trash_df has `r nrow(trash_df)` rows and `r ncol(nyc_tran)` columns. It is a `r nrow(trash_df)`✖`r ncol(trash_df)` table.**\
The variables in the dataset are `r names(trash_df)`, in which, there are mainly three types of trash wheels in the data frame, which are Mr. Trash Wheel, Professor Trash Wheel and Gwynnda Trash Wheel. The variable numbers shows the exact number of trash that the dumpster collect. Home_powered means Each ton of trash equates to on average 500 kilowatts of electricity.  An average household will use 30 kilowatts per day. \

### what was the total weight of trash collected by Professor Trash Wheel?
The total weight of trash Professor Trash Wheel collect is `r sum(prof_trash$weight_tons)` tons.

### What was the total number of cigarette butts collected by Gwynnda in June of 2022?
The total number of cigarette butts collected by Gwynnda in June of 2022 is `r sum(gwy_trash$numbers[gwy_trash$type_of_trash == "cigarette_butts" & gwy_trash$month == "June" & gwy_trash$year == "2022"])`

# Problem 3
## Part 1: create a single, well-organized dataset with all the information 
First of all, read all these tables.
```{r}
bakers = read_csv("./data of hw2/gbb_datasets/bakers.csv") |>
  janitor::clean_names()
bakes = read_csv("./data of hw2/gbb_datasets/bakes.csv")|>
  janitor::clean_names()
result = read_csv("./data of hw2/gbb_datasets/results.csv", skip = 2, na = "NA")|>
  janitor::clean_names() |>
  mutate(
    result = case_match(
      result,
      "IN" ~ "stayed in",
      "OUT" ~ "Eliminated",
      "STAR BAKER" ~ "Star Baker", 
      "WINNER" ~ "Series Winner",
      "Runner-up" ~ "Series Runner up",
      "WD" ~ "withdrew")
    )
```

## Wrangle through the datasets

```{r}
bakers = rename(bakers, baker_full_name = baker_name) |>
  mutate(baker_first_name = sapply(strsplit(baker_full_name, " "), function(x) x[1])) |>
  select(baker_full_name, baker_first_name, everything())
bakes = rename(bakes, baker_first_name = baker)
result = rename(result, baker_first_name = baker)
```
see if the data in the bakes and result set are correct
```{r}
anti_join(bakes, bakers, by = "baker_first_name")
```
For "Jo" in bakes, I find a strange ""across the Jo, so I tried to change it into Jo and do anti join again:
```{r}
bakes = bakes |>
  mutate(baker_first_name = recode(baker_first_name, "\"Jo\"" = "Jo"))
```
Let's see what is in result but not in bakers
```{r}
anti_join(result, bakers, by = "baker_first_name")
```
It is shown that the person who has a first name Joanne is not in the list of bakers but in the list of result. The person Joanne is shown in series 2, episode 1~8, it is just the same situation with Jo as it listed in the bakes set. If I use it reversely...
```{r}
anti_join(bakers, result, by = "baker_first_name")
```
So I strongly suspect that the person Joanne in result set is the Jo in bakers and bakes datasets.
```{r}
result = result |>
  mutate(baker_first_name = recode(baker_first_name, "Joanne" = "Jo"))
```
So far, all these datasets are clean and correct. Let's merge them together. 
## Combine the 3 datasets
```{r}
baker_df_all = left_join(bakers,result, by = c("baker_first_name","series"))  |>
  left_join(bakes, by = c("baker_first_name","series","episode" )) |>
  select(baker_full_name, baker_first_name, baker_age, baker_occupation, hometown, series,episode, signature_bake, show_stopper, everything())
baker_df_all
```
So, in this data set, I've conclude all the bakers information (full names, first names, age, occupation and hometown) and the series and episode they take part in the show. I've also shown the signature bake and show stopper of their bake in each episode. The technical and the result of them either.

## Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10
```{r}
star_winner = baker_df_all |>
  filter(series >= 5 & series <= 10) |>
  filter(result %in% c("Star Baker","Series Winner" )) |>
  arrange(series, episode)
star_winner
```
As you can see from this table, **Most of the people who end up winning series winners have taken more than one star baker in the first few episodes of this season** (which is quite predictable), such as Nancy in Season 5, Nadiya in Season 6, Candice in Season 7, Sophie in Season 8, and Rahul in Season 9, but there was a surprise, in season 10, **Steph** had a total of **4 star bakers**, which made him the strongest candidate for series winner, but in episode 10 the series winner was David.

## Now for the viewers!
```{r}
viewers = read_csv("./data of hw2/gbb_datasets/viewers.csv", na = "NA")|>
  janitor::clean_names() |>
  pivot_longer(
    series_1:series_10,
    names_to = "series",
    values_to = "viewership",
    names_prefix = "series_"
  ) |>
  select(series, episode, viewership) |>
  mutate(series = as.numeric(series)) |>
  arrange(series, episode)
head(viewers, n = 10)
```

### Next, calculate the average viewership in Season 1 and Season 5.
Notice: There are some NA values in the dataset. 
The average viewership in Season 1 is `r mean(viewers$viewership[viewers$series == 1], na.rm = TRUE)`.\
The average viewership in Season 5 is `r mean(viewers$viewership[viewers$series == 5], na.rm = TRUE)`.















